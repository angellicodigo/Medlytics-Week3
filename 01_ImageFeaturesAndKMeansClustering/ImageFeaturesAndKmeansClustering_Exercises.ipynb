{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Introduction\n\nIn this notebook you will be creating your own Kmeans algorithm (and comparing to the sci-kit Kmeans algorithm) and extracting different features from the same dataset used in the tutorial. As usual, we begin by importing anything we are going to need.",
   "metadata": {
    "id": "Soed7Gx8F1gb",
    "colab_type": "text",
    "cell_id": "00000-5ba4d842-a26e-46e6-903e-7bcc437a2b4e",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 165.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9f8c623d8a4e47a09a3806f073c91774",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "966296c",
    "execution_start": 1658847823052,
    "execution_millis": 9765,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 614.1875
   },
   "source": "!pip install scikit-image # Keep",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting scikit-image\n  Downloading scikit_image-0.19.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting imageio>=2.4.1\n  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tifffile>=2019.7.26\n  Downloading tifffile-2022.5.4-py3-none-any.whl (195 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 KB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting PyWavelets>=1.1.1\n  Downloading PyWavelets-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-image) (1.8.1)\nCollecting networkx>=2.2\n  Downloading networkx-2.8.5-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-image) (9.1.1)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-image) (21.3)\nRequirement already satisfied: numpy>=1.17.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-image) (1.22.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\nInstalling collected packages: tifffile, PyWavelets, networkx, imageio, scikit-image\nSuccessfully installed PyWavelets-1.3.0 imageio-2.20.0 networkx-2.8.5 scikit-image-0.19.3 tifffile-2022.5.4\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "91f9c16fe0ac4ee687653e624e1475e8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1fb5288f",
    "execution_start": 1658841446163,
    "execution_millis": 1975,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 589.984375
   },
   "source": "!pip install skimage # Keep",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting skimage\n  Using cached skimage-0.0.tar.gz (757 bytes)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m *** Please install the `scikit-image` package (instead of `skimage`) ***\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m\u001b[?25h",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QLIvL-G8efUF",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00001-c8275f8d-2270-4f3a-88c4-73ba883ec939",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7eb1c062",
    "execution_start": 1658847832820,
    "execution_millis": 3263,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 567
   },
   "source": "# Basic operating system (os), numerical, and plotting functionality\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# scipy statistics functions\nfrom scipy.stats import mode\nfrom scipy.stats import moment\n\n# scikit-learn data utilities\nfrom sklearn.datasets import make_blobs\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\n# Color transformations\nfrom skimage.color import rgb2lab\n\n\n# Feature extractors and classification algorithm\nfrom skimage.feature import graycomatrix, graycoprops\nfrom skimage.feature import local_binary_pattern\nfrom sklearn.cluster import KMeans\n\n# scikit-learn performance metric utilities\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import completeness_score",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RJ3JHQ21IW9_",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00002-777b8b80-5adb-4193-8762-b8b441f90bb1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "46fdeac7",
    "execution_start": 1658847878044,
    "execution_millis": 69,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Set plotting preferences\nimport matplotlib\n%matplotlib inline\nfont = {'family' : 'sans-serif',\n        'weight' : 'normal',\n        'size'   : 16}\nmatplotlib.rc('font', **font)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Write Your Own Kmeans Algorithm\n\nYou can learn more about Kmeans here: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html \n",
   "metadata": {
    "id": "Bgrr6RhOtRRM",
    "colab_type": "text",
    "cell_id": "00003-ec521d21-cea6-49f5-a222-22e14d912127",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 142.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Building Your kmeans Function\nIn the following code cells, you will flesh out the necessary components of the Kmeans algorithm. Look for the marker to `-999` indicate lines that need to be completed.",
   "metadata": {
    "id": "mnNIWL9uItaE",
    "colab_type": "text",
    "cell_id": "00004-8e9b24cd-bd96-4acb-a38b-2f97aae16577",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 130.796875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JF9hgIGiQdTn",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00005-48526ca9-e4df-413d-bc3c-c62237f5201d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d2f273b0",
    "execution_start": 1658847880593,
    "execution_millis": 7,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 801
   },
   "source": "def get_distances(data, cluster_centers):\n    \"\"\"Computes the distance between each data point an a cluster center\"\"\"\n    # Count the number of data points and number  of clusters expected\n    num_dim, num_points = data.shape\n    _, num_clusters = cluster_centers.shape\n    # Initialize an array to store distances between clusters centers and points\n    distances = np.zeros((num_clusters, num_points))\n\n    # Loop over each cluster and perform distance calculations\n    for iclust in range(num_clusters):\n        # Grab and reshape the cluster center at this index\n        this_center = cluster_centers[:, iclust].reshape((num_dim, 1))\n        # Compute the positional difference between data and cluster center\n        data_offset = data - this_center # <-- Modify this line to get the positional offset\n        # Use the Euclidean metric to compute the distance\n        # distance = sqrt(sum_i { (p_i - p_i_0)**2} ) <-- where `p_i` indicates\n        #                                                 the position along the\n        #                                                 `i-th` dimension.\n        data_offset_sq = (data_offset)**2 # <-- Compute the offset squared on this line\n\n        # We are going to accelerate the summation process by using the `axis=0`\n        # keyword argument of the `np.sum` function. This causes the `np.sums\n        # function to add all the elements along the first (0-th) axis. This is\n        # the axis that indexes the (x, y, z, etc...) of our data. Thus, in the\n        # two dimensional case, this is equivalent to the familiar\n        #\n        # sqrt((x - x0)**2 + (y - y0)**2) <-- Pythagorean theorem\n        #\n        # In three dimensions it is\n        #\n        # sqrt((x - x0)**2 + (y - y0)**2 + (z - z0)**2)\n        #\n        # and so on... Using the `axis` keyword, we can allow `data` to\n        # represent positions in *any* number of dimensions. You can learn more\n        # here: https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n        this_distances = np.sqrt(np.sum(data_offset_sq, axis=0))\n\n        # Store the computed distances in the output array\n        distances[iclust] = this_distances\n\n    return distances",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nTRFT5IzQiVD",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00006-f3e854a4-3ad7-4f1d-a222-f204f3de0fd1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "83ff9fb6",
    "execution_start": 1658848070262,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 459
   },
   "source": "def get_new_cluster_centers(data, cluster_indices):\n    \"\"\"Computes cluster center using the indices assigned to each data point\"\"\"\n    # Count the number of clusters to be assigned\n    num_dim, num_points = data.shape\n    num_clusters = np.unique(cluster_indices).size\n\n    # Initialize an array to store the cluster centers\n    cluster_centers = np.zeros((num_dim, num_clusters))\n\n    # Loop over each cluster and locate which data points \n    for iclust in range(num_clusters):\n        # We can use the `np.where` function to grab the indices at which\n        # the values of `nearest_cluster_ind` is equal to cluster index `iclust`\n        this_cluster_mask = iclust == cluster_indices   # <-- Locate where the cluster index is equal to this cluster index\n        this_cluster_inds = np.where(this_cluster_mask)[0]\n        # Compute the mean position of the data points at the indices now stored\n        # in the `this_cluster_inds` variable. Try using that `axis` keyword!\n        this_center = np.mean(data[:, this_cluster_inds], axis = 1) # <-- Compute the mean position\n        # Store this cluster center in the output array\n        cluster_centers[:, iclust] = this_center\n\n    return cluster_centers",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QtZNcrOjI8CL",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00007-3264d1b8-5f45-423d-a5f8-6d06efde4e84",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7298e86d",
    "execution_start": 1658847885168,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 873
   },
   "source": "def my_kmeans_function(data, num_clusters, num_iterations):\n    \"\"\"\n    Applies the Kmeans clustering algorithm to the `data`\n\n    Arguments\n    ---------\n    data : ndarray, shape (num_dim, num_points)\n        All of the data to be clustered.\n\n    num_clusters : int\n        The number of clusters to use in the clustering process\n\n    num_iterations : int\n        The number of times to loop over the clustering process\n    \"\"\"\n    # Get number of dimensions for data\n    num_dim, num_points = data.shape\n\n    # We can use some randomly selected data points as starting guesses for\n    # the cluster centers. These are guaranteed to be within the data range!\n    random_data_inds = np.random.choice(num_points, num_clusters, replace=False)\n    cluster_centers = data[:, random_data_inds]\n\n    # # Generate some random cluster center starting points. We are using that\n    # # nifty `axis` keyword described in the functions above.\n    # dmin = data.min(axis=1).reshape((num_dim, 1))   # Data min along each dim.\n    # dmax = data.max(axis=1).reshape((num_dim, 1))   # Data max along each dim.\n    # drange = (dmax - dmin)                          # Data range along each dim.\n\n    # # Generate some random starting points, then scale and re-center them\n    # cluster_centers = np.random.random(size=(num_dim, num_clusters))\n    # cluster_centers = drange*cluster_centers + dmin\n\n    # Perform the requested number of iterations\n    for iiter in range(num_iterations):\n        # Compute the distance betwen each data-point and cluster-center\n        distances = get_distances(data, cluster_centers) # <-- use one of your functions from above\n        # Grab the cluster index for which the euclidian distance is smallest\n        # In case you did not know about the `argmin` method, it is pretty neat:\n        # https://numpy.org/doc/stable/reference/generated/numpy.argmin.html\n        nearest_cluster_ind = np.argmin(distances, axis=0)\n        # Compute new cluster cunters based on nearest cluster indexing\n        cluster_centers = get_new_cluster_centers(data, nearest_cluster_ind) # <-- use one of your functions from above\n\n    return cluster_centers",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Generate and Visualize Some Clustered Data\n\nConveniently, scikit-learn provides a function to generate some \"blobs\" of clustered data for us to test our Kmeans algorithm.",
   "metadata": {
    "id": "FinwX0jdFsak",
    "colab_type": "text",
    "cell_id": "00008-b9ea194c-b9dc-4b74-bcaa-b2cfb13111e7",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 130.796875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kkFn8yTGxkCq",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00009-b10a9a27-05f0-4f37-839c-cb67b6bfaa4a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "249dcf79",
    "execution_start": 1658847888106,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "# Creating and visualizing a random datset using sklearn's make_blobs\ndata, actual_cluster = make_blobs(n_samples=800, centers=3, cluster_std=.08,\n                                  random_state=0)\n\n# Transpose data to be a bit more consistent with conventions in this notebook\ndata = data.T",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-WUiEnO5t90y",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "e379fc2e-d4d2-42d0-e574-1f219e381005",
    "cell_id": "00010-41eb28a9-578f-4b37-8fc2-13ed233982ac",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1d840667",
    "execution_start": 1658848074435,
    "execution_millis": 40,
    "owner_user_id": "621726e3-8134-49a7-876e-c70857c125a9",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 615.6875
   },
   "source": "# Apply the Kmeans algorithm from above\nnum_clusters = 3\nnum_iterations = 10\ncluster_centers = my_kmeans_function(data, num_clusters, num_iterations)\n\n# Estimate which cluster each datapoint belongs to using nearest neighbor from\n# estimated cluster centers. We can just repeat some lines from our Kmeans...\ndistances = get_distances(data, cluster_centers)\nnearest_cluster_ind = np.argmin(distances, axis=0)\n\n# Loop over each cluster and build a dictionary mapping from the cluster index\n# in `nearest_cluster_ind` to the actual cluster number used when generating the\n# original data.\nest_to_true_map = {}\nfor iclust in range(num_clusters):\n    # Grab the *most common* true cluster number associated with this index\n    this_cluster_mask = nearest_cluster_ind == iclust\n    this_est_to_true = mode(actual_cluster[np.where(this_cluster_mask)])[0][0]\n    est_to_true_map[iclust] = this_est_to_true\n\n# Now, apply this mapping to the data in `nearest_cluster_ind`\n# Here, we are using a technique called \"list comprehension.\" It is *also*\n# pretty nifty and worth knowing about. You can read more here:\n# https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions\nestimated_cluster = np.array([est_to_true_map[i] for i in nearest_cluster_ind])\n\n# Compute a classification accuracy\naccuracy = accuracy_score(actual_cluster, estimated_cluster)\nprint(accuracy)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Let's visualize the results of this Kmeans clustering attempt.",
   "metadata": {
    "id": "18cNsqMlgCse",
    "colab_type": "text",
    "cell_id": "00011-e69417d8-44c4-4ecb-a151-614a8a36709a",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HoVU2byVgBZH",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "outputId": "6f69c1c4-1e4e-484d-c9f7-31dd625755c4",
    "cell_id": "00012-ec127fb8-2a72-4000-9838-399231bd9d92",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "afc2ac0e",
    "execution_start": 1658841198907,
    "execution_millis": 356,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 854,
    "deepnote_output_heights": [
     397
    ]
   },
   "source": "# Visualize that data\nfig, ax_arr = plt.subplots(1, 2, figsize=(16, 8))\n\n# Loop over each cluster and plot its data (with aunique color!)\nfor iax in range(2):\n    for iclust in np.unique(actual_cluster):\n        if iax == 0:\n            cluster_data = data[:, np.where(actual_cluster == iclust)]\n        elif iax == 1:\n            cluster_data = data[:, np.where(estimated_cluster == iclust)]\n\n        # Actually plat the clusters\n        ax_arr[iax].scatter(*cluster_data)\n\n    # Add some annotation and formatting\n    ax_arr[iax].axis('equal')\n    ax_arr[iax].set_title(['True Clusters', 'Predicted Clusters'][iax])\n    ax_arr[iax].set_xlabel('X')\n    ax_arr[iax].set_ylabel('Y')\n\nplt.show()",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 943,
       "height": 511
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "This Kmeans example was initialized using some blobs with a small amount of overlap. What happens if you adjust the parameters of the cluster-generating code.\n\n* Broader clusters `cluster_std`: Worse accuracy\n* More data points `n_samples`: Worse accuracy\n* Number of blobs `centers`: 3 is ideal, any more will worsen the accuracy\n\n\n(**YOUR ANSWER ABOVE**)",
   "metadata": {
    "id": "vQUySMRNayzw",
    "colab_type": "text",
    "cell_id": "00013-04e1dcde-2f5b-48da-8e66-3aea2e26493f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 198.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "# More Feature Extraction\n\nAs we saw in the last section of the tutorial notebook, it is possible to extract a set of descriptive features from an image (much like was done with 1D signals in the previous week). In the following section, we will work through several examples of feature extraction and image classification with Kmeans using those extracted features.",
   "metadata": {
    "id": "WMVJLALtuqt7",
    "colab_type": "text",
    "cell_id": "00014-bd6d83f5-d71e-40f7-b5dd-27cc29396585",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 187.59375
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Histogram Features\n\nThere are several histogram features that can be applied in the context of image processing. \n\nOne featue is the mean, or intensity value of all of the pixels in the image. This can be thought of as the average brightness of the entire image.\n\nAnother feature is the variance, which explains how close pixel intensity values are to each other. A low variance would explain that most of the pixel values are extremely close together, while a high variance would indicate that pixel values vary more and are spead around the mean. \n\nThe standard deviation is the the variance squared.\n\nYou can read more about histogram features in the context of pictures here: http://www.giassa.net/?page_id=470",
   "metadata": {
    "id": "YvaM291Iuuq3",
    "colab_type": "text",
    "cell_id": "00015-bdf876a1-fed6-42f8-bbff-05cd13e6bb02",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 343.578125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ywKX7UQH2GOu",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "outputId": "47f9e104-2675-4216-a524-bd69b2c12c35",
    "cell_id": "00016-c82f94c6-8a79-43de-ad11-4dd706d60455",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ae7c9426",
    "execution_start": 1658841199270,
    "execution_millis": 6781,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 536.96875
   },
   "source": "# Define the current directory and the directory where the files to download can\n# be found\ncurrent_dir = '/'\nremote_path = 'https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/'\n\ndata_dir = '/crc_data'\nif not os.path.isdir(data_dir):\n  os.mkdir(data_dir)\n\nos.chdir(data_dir)\nfor ii in range(1, 6):\n    basename = f'rgb0{ii}.npz'\n    filename = os.path.join(remote_path, basename)\n\n    if not os.path.isfile(basename):\n      cmd = f'wget {filename}'\n      print(cmd)\n      os.system(cmd)\n\nos.chdir(current_dir)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "wget https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/rgb01.npz\nwget https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/rgb02.npz\nwget https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/rgb03.npz\nwget https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/rgb04.npz\nwget https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/rgb05.npz\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6iFg1G_7GUA9",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00017-3832b300-bee6-4fee-8321-5c4dc162c3db",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "50a6f363",
    "execution_start": 1658841206138,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 963
   },
   "source": "# Define a function to load the data from the assumed download path\ndef load_images(colorspace='rgb'):\n    colorspace_lower = colorspace.lower()\n    if colorspace_lower not in ['rgb', 'gray', 'grey', 'lab']:\n        raise ValueError(f'`colorspace` value of {colorspace} not recognized')\n\n    filename = os.path.join(data_dir, 'rgb01.npz')\n    print(f'loading {filename}')\n    tmp = np.load(os.path.join(data_dir, 'rgb01.npz'), allow_pickle=True)\n\n    images = tmp['rgb_data']\n    if colorspace_lower == 'rgb':\n        pass\n    elif colorspace_lower in ['gray', 'grey']:\n        images = np.mean(images, axis=-1)\n    elif colorspace_lower == 'lab':\n        images = rgb2lab(images)\n\n    labels = tmp['labels']\n    \n    label_to_str = tmp['label_str']\n    label_to_str = label_to_str.tolist() # Convert label_to_str into a dict\n\n    print('Loaded images with shape {}'.format(images.shape))\n    del tmp\n\n    for ii in range(2,6):\n        filename = os.path.join(data_dir, f'rgb0{ii}.npz')\n        print(f'loading {filename}')\n        tmp = np.load(filename, allow_pickle=True)\n\n        these_images = tmp['rgb_data']\n        if colorspace_lower == 'rgb':\n            pass\n        elif (colorspace_lower == 'gray') or (colorspace_lower == 'grey'):\n            these_images = np.mean(these_images, axis=-1)\n        elif colorspace_lower == 'lab':\n            these_images = rgb2lab(these_images)\n\n        images = np.append(images, these_images, axis=0)\n        labels = np.append(labels, tmp['labels'], axis=0)\n\n        print('Loaded images with shape {}'.format(these_images.shape))\n        del tmp\n\n    images = images.astype(np.float)\n    print('Final image data shape: {}'.format(images.shape))\n    print('Number of image labels: {}'.format(*labels.shape))\n\n    return images, labels",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p1stCgsGwM3h",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "7ae8ef06-1b30-4f56-dd27-14eb85f917be",
    "cell_id": "00018-51f05d07-99d0-4697-90d0-35f25e59b0b9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a2718132",
    "execution_start": 1658841206145,
    "execution_millis": 1841,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 427.921875
   },
   "source": "# Load in the images and convert them to L*a*b* (see function from tutorial)\nimages_color, labels = load_images(colorspace='rgb') # <-- Come back and try in RGB colorspace\nnum_images, num_y, num_x, num_ch = images_color.shape",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "loading /crc_data/rgb01.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb02.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb03.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb04.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb05.npz\nLoaded images with shape (1000, 150, 150, 3)\n<ipython-input-12-cf8a35a87722>:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  images = images.astype(np.float)\nFinal image data shape: (5000, 150, 150, 3)\nNumber of image labels: 5000\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nTEfb-vByEjt",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00019-6ff86cab-7ab7-4300-a68f-22ab104970a1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5941dec",
    "execution_start": 1658841207990,
    "execution_millis": 3158,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 549
   },
   "source": "# Initialize an array to store the features\nnum_features = 3*num_ch     # We are computing three features per channel\nhist_features = np.zeros((num_images, num_features))\n# Compute histogram features\nfor i_img in range(num_images):\n    # Compute the mean of each of the image color channels. You are going to\n    # need to grab the current image (using `i_img`), then grab all of the\n    # rows and columns (using the `:` slicing operator), and grab one of\n    # the three color channels on which to compute the mean value.\n    #\n    # You can use `np.mean` on the flattened channel data for this image\n    hist_features[i_img, 0] = np.mean(images_color[i_img][:,:,0]) # <-- populate with proper argument\n    hist_features[i_img, 1] = np.mean(images_color[i_img][ :,:,1]) # <-- populate with proper argument\n    hist_features[i_img, 2] = np.mean(images_color[i_img][:,:,2]) # <-- populate with proper argument\n\n    # Compute the standard deviation of each of the image color channels\n    # You can use `np.std` on the same, flattened channel data for this image\n    hist_features[i_img, 3] = np.std(images_color[i_img][:,:,0]) # <-- populate with proper function *and* argument\n    hist_features[i_img, 4] = np.std(images_color[i_img][:,:,1]) # <-- populate with proper function *and* argument\n    hist_features[i_img, 5] = np.std(images_color[i_img][:,:,2]) # <-- populate with proper function *and* argument\n\n    # Compute the \"second moment\" (variance) of each of the image color channels\n    # You can use `np.var` on the same, flattened channel data for this image\n    hist_features[i_img, 6] = np.var(images_color[i_img][:,:,0]) # <-- populate with proper function *and* argument\n    hist_features[i_img, 7] = np.var(images_color[i_img][:,:,1])# <-- populate with proper function *and* argument\n    hist_features[i_img, 8] = np.var(images_color[i_img][:,:,2]) # <-- populate with proper function *and* argument\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5g2Va8kUyG-i",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00020-c4206e0a-5cf8-4e9c-87af-bb6ce1af889e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a7b14a33",
    "execution_start": 1658841211153,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "# Apply a train_test_split here\nX_train, X_test, y_train, y_test = train_test_split(hist_features, labels, test_size=0.25)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-15x6-1DyUha",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00021-f1040fa5-d102-433a-8e62-14ca21ac565a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f535c592",
    "execution_start": 1658841211158,
    "execution_millis": 275,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "# Apply the (*much faster*) scikit-learn Kmeans algorithm to get the image\n# data clustering (You can experiment with different K-means algorithms (auto,\n# full, or elkan)). You can learn more about these here:\n# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n\n# Cluster the images using the KMeans algorithm\nkmeans_object = KMeans(algorithm='elkan', n_clusters=8, max_iter=1)\nkmeans_estimator = kmeans_object.fit(X_train) ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6aLMCbMdz7ZS",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00022-73ed45e2-04d5-4229-8274-0f8b4ab3ae68",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c48a7f67",
    "execution_start": 1658841211437,
    "execution_millis": 65,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "# Predict using Kmeans estimator\npreds = kmeans_estimator.predict(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now that we have actually made our predictions for which cluster each of the test images belongs to, we need to convert cluster numbers into classification label numbers. To do that, we will examine the most *common* label within each cluster and assume that is the correct label to associate with the cluster.",
   "metadata": {
    "id": "39OTzd64limS",
    "colab_type": "text",
    "cell_id": "00023-3e195b80-e90a-4a87-80a8-7202f25f1044",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 97.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i5TC-Lc46ZiS",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "outputId": "aaa78274-e774-47a6-8644-4d44df6d0d29",
    "cell_id": "00024-ad12b504-dcc4-4cdd-b8bc-f03bcadcaed4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "34581889",
    "execution_start": 1658841211512,
    "execution_millis": 22,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 591.5625
   },
   "source": "# Initialize an array to store the classification prediction labels\npred_labels = np.zeros_like(preds)\n\n# Loop over each cluster\nfor icluster in range(8):\n    # Build a mask indicating where the cluster number is equal to `icluster`\n    mask = (preds == icluster)\n\n    # Handle the cases where this cluster was never predicted for test data\n    if np.sum(mask) == 0:\n        print(f'Cluster {icluster} is not populated by test data')\n        continue\n\n    # Assign the *most common* label to *this*\n    this_label = mode(y_test[mask]).mode[0]\n    pred_labels[mask] = this_label\n\n    # Printe the association being made for some transparency to the user\n    print(f'Cluster {icluster} gets label {this_label}')\n    ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cluster 0 gets label 5\nCluster 1 gets label 2\nCluster 2 gets label 6\nCluster 3 gets label 7\nCluster 4 gets label 2\nCluster 5 gets label 4\nCluster 6 gets label 1\nCluster 7 gets label 3\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rQOTrc0Y58Im",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "3f9844c5-ec45-40a5-a4a4-90a4a1ffea2d",
    "cell_id": "00025-6693913d-0bf8-45e1-9559-9ad897d55824",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fc6727da",
    "execution_start": 1658841211535,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "source": "# Compute the accuracy\nacc_hist = accuracy_score(y_test, pred_labels)\nprint(acc_hist)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "0.4016\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Another metric worth considering is the \"completeness score.\" This is a measure of how frequently the images of a single class were assigned to *multiple* clusters. You can read more about this metric at the scikit-learn page for [completeness score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html).",
   "metadata": {
    "id": "ijkPy_60mhtb",
    "colab_type": "text",
    "cell_id": "00026-323cd907-5819-4820-9c7a-fc7391056e7e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dxPSCjuuyZ1H",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "1087d51d-0d91-4794-e0d4-3a57497c6216",
    "cell_id": "00027-f4d27617-4811-4a02-8e34-d394f38d4af6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "44a6de2b",
    "execution_start": 1658841211594,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# Compute the completeness score\ncomp_hist = completeness_score(y_test, pred_labels)\nprint(comp_hist)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "0.35836247890789147\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "If you're getting tired of waiting for KMeans to run, you can use the MiniBatchKMeans function to perform KMeans using batched sub-sets of the training data. This will run significantly faster at the cost of some accuracy. You will also need to go back and change all of the `KMeans()` calls to `MiniBatchKMeans()`.",
   "metadata": {
    "id": "iBkFO0xHpbGS",
    "colab_type": "text",
    "cell_id": "00028-6ff2a7f5-7472-4998-bb6a-92fff0905d2c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6ixxInzN5uV9",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00029-27f351d3-159e-405b-b1c3-bfbd18a8ccc0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ff5e6e7",
    "execution_start": 1658841211640,
    "execution_millis": 60307555,
    "deepnote_cell_type": "code"
   },
   "source": " # A faster, potentially less accurate Kmeans\n from sklearn.cluster import MiniBatchKMeans",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Repeat in RGB\nThese histogram features can also be computed using RGB colorspace rather than L* a* b* colorspace. How does that affect the accuracy of the classification?",
   "metadata": {
    "id": "EZrLHVIB1Zfx",
    "colab_type": "text",
    "cell_id": "00030-51a0233d-217e-4add-8a79-4e3a05c8a7ef",
    "owner_user_id": "8393c91e-f14f-476f-8f19-49bd01a13be6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Local Binary Patterns\n\nAnother feature extraction procedure to consider involves the computation of the \"Local Binary Pattern.\" This procedure computes a local representation of texture by comparing a pixel with its surrounding pixels and converting these neigbor pixel values into binary digits. You can read more about Local Binary Patterns (LBP) here:\n\nhttps://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n\nAnd here:\n\nhttps://scikit-image.org/docs/stable/auto_examples/features_detection/plot_local_binary_pattern.html\n",
   "metadata": {
    "id": "jemScTEvycxX",
    "colab_type": "text",
    "cell_id": "00031-4fc49f12-683a-4619-9e4c-118547c90603",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5tbOxfACystN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "e6cfa02c-06ce-485c-dc8f-12dc98813699",
    "cell_id": "00032-f9a23cba-a3f7-4e65-b88e-b374594e17df",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3cde0a19",
    "execution_start": 1658841211641,
    "execution_millis": 1498,
    "deepnote_cell_type": "code"
   },
   "source": "# Clear out the old data\ntry:\n    del X_train_ab, X_test_ab, y_train, y_test\nexcept:\n    pass\ntry:\n    del images_color\nexcept:\n    pass\n\n# *** OKAY, YOUR TURN! ***\n# Refer to the examples above and in the tutorial to load the RGB images\nimages_color, labels = load_images(colorspace='rgb') # <-- Use the loading function\n\n# Grab just the red channel since that's where most of the information is\nimages_red = images_color[:,:,0] # <-- Grab just the *red* channel of these images\ndel images_color",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "loading /crc_data/rgb01.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb02.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb03.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb04.npz\nLoaded images with shape (1000, 150, 150, 3)\nloading /crc_data/rgb05.npz\nLoaded images with shape (1000, 150, 150, 3)\n<ipython-input-12-cf8a35a87722>:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  images = images.astype(np.float)\nFinal image data shape: (5000, 150, 150, 3)\nNumber of image labels: 5000\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m1n1hQyjyis8",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00033-e2808a18-ddea-4fc1-8fdc-5855ca719413",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d77a3d00",
    "execution_start": 1658841213143,
    "execution_millis": 951,
    "deepnote_cell_type": "code"
   },
   "source": "# Initialize array to store features\nnum_images, num_y, num_x = images_red.shape\nlbp_features = np.zeros_like(images_red)\n\n# Loop over each image and compute the local binary pattern features\nfor i_img in range(num_images):\n    lbp_features[i_img] = local_binary_pattern(images_red[i_img], P=16, R=2,\n                                               method='uniform')\n\n# Flatten into a vector\nlbp_features = lbp_features.reshape((num_images, num_y*num_x))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L8FqlAA20BGC",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00034-9b39f125-c2ec-4738-992d-92cda39aa99a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5f52b26",
    "execution_start": 1658841214105,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "# Apply train_test_split\nX_train, X_test, y_train, y_test = train_test_split(lbp_features, labels)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bi5TMu2vz01H",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00035-cc496a08-a39a-4f55-8309-3d0cc1e6838f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "200aa350",
    "execution_start": 1658841214116,
    "execution_millis": 1636,
    "deepnote_cell_type": "code"
   },
   "source": "# KMeans fit\nkmeans = KMeans(n_clusters=8, max_iter=10).fit(X_train)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CCfbCGAbz2kD",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00036-1df41eed-f38d-4fdb-92a5-b7097d24d90f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "845e1a8f",
    "execution_start": 1658841215756,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "source": "# KMeans predict\npreds = kmeans.predict(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9mfWSh9W0N_P",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "outputId": "c843ba25-9985-47e1-c325-24e1a5a95af7",
    "cell_id": "00037-f79e1e05-29ae-47b3-9d52-94efc911b089",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fac71682",
    "execution_start": 1658841215768,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": "# Apply clustering estimation\n# Initialize an array to store the classification prediction labels\npred_labels = np.zeros_like(preds)\n\n# Loop over each cluster\nfor icluster in range(8):\n    # Build a mask indicating where the cluster number is equal to `icluster`\n    mask = (preds == icluster)\n\n    # Handle the cases where this cluster was never predicted for test data\n    if np.sum(mask) == 0:\n        print(f'Cluster {icluster} is not populated by test data')\n        continue\n\n    # Assign the *most common* label to *this*\n    this_label = mode(y_test[mask]).mode[0]\n    pred_labels[mask] = this_label\n\n    # Printe the association being made for some transparency to the user\n    print(f'Cluster {icluster} gets label {this_label}')\n    ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cluster 0 gets label 7\nCluster 1 gets label 1\nCluster 2 gets label 1\nCluster 3 gets label 6\nCluster 4 gets label 0\nCluster 5 gets label 5\nCluster 6 gets label 6\nCluster 7 gets label 7\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "te3rv7iM0QXS",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "182d3fa2-8862-44e8-f323-b3c4e646b62f",
    "cell_id": "00038-fb99e6bf-0b3c-482b-a9cf-129577ded594",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fc6727da",
    "execution_start": 1658841215777,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "# Compute the accuracy\nacc_hist = accuracy_score(y_test, pred_labels)\nprint(acc_hist)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "0.3504\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "cdd09c21cd57464789ebc13a486b26b9",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2b340762",
    "execution_start": 1658841215831,
    "execution_millis": 4671,
    "deepnote_cell_type": "code"
   },
   "source": "try:\n    del X_train, X_test, y_train, y_test\nexcept:\n    pass\ntry:\n    del images_color\nexcept:\n    pass\n\n# Now reload the grayscale images\nimages_gray, labels = load_images(colorspace='gray')\nnum_images = len(labels)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "loading /crc_data/rgb01.npz\nLoaded images with shape (1000, 150, 150)\nloading /crc_data/rgb02.npz\nLoaded images with shape (1000, 150, 150)\nloading /crc_data/rgb03.npz\nLoaded images with shape (1000, 150, 150)\nloading /crc_data/rgb04.npz\nLoaded images with shape (1000, 150, 150)\nloading /crc_data/rgb05.npz\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9970c065e1094e72a3987ca17cdefa41",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "fecafe88",
    "execution_start": 1658780912859,
    "execution_millis": 159308,
    "deepnote_cell_type": "code"
   },
   "source": "# Initialize an array in which to store the image features\ncomatrix_features = np.array([])\n\n# Loop over each image in the training set\nfor k in range(num_images):\n  # Compute the grey-lever co-occurence matrix for this image\n  # NOTE: For some reason the scikit-image.greycomatrix function specifies pixel\n  # offsets in terms of distance and angles. Here we use a distance of 1 pixel\n  # and angular offsets of 0 and pi/2 to specify the offsets (dx = 1, dy = 0)\n  # and (dx = 0, dy = 1).\n  comatrix = graycomatrix(images_gray[k].astype('int'), distances=[1], angles=[0, np.pi/2], levels = 256)\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'contrast'))\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'dissimilarity'))\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'homogeneity'))\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'energy'))\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'correlation'))\n  comatrix_features = np.append(comatrix_features, graycoprops(comatrix, 'ASM'))\n\n# Reshape the array of features so that first axis is the image index and second\n# axis is the feature index.\ncomatrix_features = comatrix_features.reshape(num_images, 12)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4ac18cedc07d4db49caedb1e927b54ae",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "e9ffb31f",
    "execution_start": 1658781072211,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "tmp = train_test_split(np.arange(num_images), comatrix_features, labels, test_size=0.25)\ninds_train, inds_test, X_train_comatrix, X_test_comatrix, y_train, y_test = tmp",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "01754f56e9f64343b2432c35ebeab35d",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cea93d4e",
    "execution_start": 1658781106669,
    "execution_millis": 1514,
    "deepnote_cell_type": "code"
   },
   "source": "kmeans_estimator = KMeans(n_clusters=8, max_iter=10).fit(X_train_comatrix)\npreds = kmeans_estimator.predict(X_test_comatrix)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c93fb40ac8b64c4a988de384085bb34e",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "86f1758c",
    "execution_start": 1658781113072,
    "execution_millis": 9,
    "owner_user_id": "2ac2a22d-c336-45ee-b1d9-9b1dedbdf54f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 629.25
   },
   "source": "pred_labels = np.zeros_like(preds)\n\n# Loop over each cluster\nfor icluster in range(8):\n    # Build a mask indicating where the cluster number is equal to `icluster`\n    mask = (preds == icluster)\n\n    # Handle the cases where this cluster was never predicted for test data\n    if np.sum(mask) == 0:\n        print(f'Cluster {icluster} is not populated by test data')\n        continue\n\n    # Assign the *most common* label to *this*\n    this_label = mode(y_test[mask]).mode[0]\n    pred_labels[mask] = this_label\n\n    # Printe the association being made for some transparency to the user\n    print(f'Cluster {icluster} gets label {this_label}')\n    # Compute the accuracy\nacc_hist = accuracy_score(y_test, pred_labels)\nprint(acc_hist)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cluster 0 gets label 7\nCluster 1 gets label 6\nCluster 2 gets label 1\nCluster 3 gets label 5\nCluster 4 gets label 4\nCluster 5 gets label 0\nCluster 6 gets label 3\nCluster 7 gets label 6\n0.36\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Conclusion\nIn the tutorial, we found that the Kmeans algorithm was able operate on the input data to classify the test images with the following accuracies:\n\n* Grayscale accuracy = 40.2%\n\n* L* a* b* accuracy = 40.5%\n(based on a* and b* color channels of images)\n\n* Co-occurence matrix accuracy = 35.76%\n\nUse this space to tabulate the accuracies for the additional features explored in this exercise notebook.\n\n* Histogram L* a* b* = 41.0%\n\n* Histogram RGB = 42.48%\n\n* Local binary pattern = 36.2%\n\n* Co-occurence matrix with different parameters = 36.0%\n\nWhich features provided highest accuracy? Why do you think this is?\n\nOur histogram that used RGB produced the highest accuracy, likely because the dataset contained images of tissues, which mainly had a red apperance (over other colors). \n",
   "metadata": {
    "id": "9V93vjBr0Wkj",
    "colab_type": "text",
    "cell_id": "00039-cc8e77e5-e1cc-4853-aea3-3a92ec01de6c",
    "owner_user_id": "7e1bf79a-8cbb-4e6d-ac8e-c6916872ecc5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 521.578125
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5c286c43-6643-4de9-bc0c-80fb67e0a715' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ImageFeaturesAndKmeansClustering_Exercises.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "deepnote_notebook_id": "ac2f0bc6-401b-49e1-b14f-69f65c5fd00b",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}